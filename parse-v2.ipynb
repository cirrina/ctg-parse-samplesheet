{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Packages\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------\n",
    "##  DEBUGGING & LOCAL RUNS \n",
    "## -------------------------------\n",
    "# .... Params uncomment when debugging on local\n",
    "os.chdir('/Users/david/tmp/') ## use if local\n",
    "sheet_name = 'CTG_SampleSheet.labsheet.test.csv' ## use if local\n",
    "\n",
    "# Get batchid from labsheet name - add to demux-samplesheet\n",
    "# batchid_sheetname=sheet_name.split(\".\")[2]\n",
    "\n",
    "# # The Sample_Project, Sample_ID, and Sample_Name columns accept alphanumeric characters, hyphens (-), and underscores (_).\n",
    "force_Sample_Name = True  # if to force Sample_Name(s) supplied in [Data] column to the same as Sample_ID\n",
    "fastq_suffix = \"_001.fastq.gz\" # \"Suffix needed to auto-generate fastq file names generated by bcl2fastq. If NULL no bam file names will be genrerated\"\n",
    "bam_suffix = \"_Aligned.sortedByCoord.out.bam\"  ## \"Suffix needed to auto generate bam file names (typically generated by STAR). If NULL no bam file names will be genrerated\"\n",
    "force_fastq_names = False # Set to true if topai overwrite fastq filenames. By defualt (fastq_1/fastq_2) columns will not be overwritten if present (even though fastq_suffix is supplied)\n",
    "force_bam_names = False # Set to true if to overwrite bam filenames. By defualt (bam) column will not be overwritten if present (even though bam_suffix is supplied)\n",
    "\n",
    "## ADD UNIQUE FASTQ IF MULTIPLE LANES * collapse lanes * Special cases when same sample is distributed over multiple lanes within a single project.\n",
    "allow_dups_over_lanes = True # If to allow duplicates (within one project) on multiple lanes. Rare on NovaSeq but can be found for S4 with lane divider. One sample may be run on both lane 1/2 or on 3/4.\n",
    "collapse_lanes = True ## Like allow_dups_over_lanes, affects project specific samplsheets NOT demux sheet.  special cases - when a single (same) sample is present in multiple lanes AND --noLaneSplitting is True in bcl2fastq. Then SampleSheet should be collapsed from Lane to individual sample (fastq R1/R2 files )\n",
    "#force_fastq_names = False\n",
    "\n",
    "cwd = os.path.basename(os.getcwd())\n",
    "runfolder_root=\"/projects/fs1/nas-sync/upload/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sample_Project': 'ProjectID', 'PipelineName': 'PipelineName', 'PipelineVersion': 'PipelineVersion', 'PipelineProfile': 'PipelineProfile', 'Sample_Species': 'Species', 'Sample_ReferenceGenome': 'ReferenceGenome', 'email_ctg_lab': 'email-ctg-lab', 'email_ctg_bnf': 'email-ctg-bnf', 'email_ctg_all': 'email-ctg-all', 'name_pi': 'name-pi', 'email_customer': 'email-customer', 'Assay': 'Assay', 'IndexAdapters': 'IndexAdapters', 'Sample_Strandness': 'Strandness', 'fragmentation_time': 'FragmentationTime', 'pcr_cycles': 'PCR-cycles', 'Sample_PairedEnd': 'PairedEnd', 'Pool_Conc_NovaSeq': 'PoolConcNovaSeq', 'Pool_Molarity_NovaSeq': 'PoolMolarityNovaSeq'}\n"
     ]
    }
   ],
   "source": [
    "## -------------------------------------\n",
    "##   LOOKUP DICTIONARIES & VARIABLES \n",
    "## -------------------------------------\n",
    "\n",
    "## Pipeline dict. check allowed Pipeline & pipeline profiles\n",
    "lookup_pipelines = {\n",
    "    'seqonly': ['bcl2fastq_default','fastq_demux','rawdata_runfolder'],\n",
    "    'ctg-rnaseq': ['rnaseq_mrna','rnaseq_total','uroscan','fastq_demux','rawdata_runfolder','rawdata'],\n",
    "    'dna-dragen': ['panel_twist_comprehensive_dragen','panel_gmck_dragen','panel_gms_dragen','bam_alignment_dragen','wgs_dragen'],\n",
    "    'demux-runfolder': ['bcl2fastq_default']\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "## a dictionary is used to find the corresponding [Data] section to a [Header] param\n",
    "## key = [Header] param name\n",
    "##  DataCol: [Data] column name\n",
    "##  Catenate: boolean if to collapse multiple entries. This is id Data column contanins multiple (non unique) values, if to collapse these in Header section with semicolon.\n",
    "##  RegExp: regexp to parse. what characters are allowed for this entry. Leave blank if to use the default character setup set in default_regexp\n",
    "##  Controlled: if the entry has a controlled vocab or not (not yet implemented)\n",
    "default_regexp='[^0-9a-zA-Z\\_\\.\\-\\+\\@\\(\\)\\;\\,\\'\\\"\\| ]+'\n",
    "\n",
    "params_dict = {\n",
    "    'ProjectID': {'DataCol': 'Sample_Project','Catenate': True,'RegExp': '[^0-9a-zA-Z\\_\\|]+','Controlled': False},\n",
    "    'PipelineName': {'DataCol': 'PipelineName','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'PipelineVersion': {'DataCol': 'PipelineVersion','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'PipelineProfile': {'DataCol': 'PipelineProfile','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'Species': {'DataCol': 'Sample_Species','Catenate': False,'RegExp': '','Controlled':False},\n",
    "    'ReferenceGenome': {'DataCol': 'Sample_ReferenceGenome','Catenate': False,'RegExp': '','Controlled':False},\n",
    "    'email-ctg-lab': {'DataCol': 'email_ctg_lab','Catenate': False,'RegExp': '[^0-9a-zA-Z\\.\\-\\_\\@\\|]+','Controlled': False},\n",
    "    'email-ctg-bnf': {'DataCol': 'email_ctg_bnf','Catenate': False,'RegExp': '[^0-9a-zA-Z\\.\\-\\_\\@\\|]+','Controlled': False},\n",
    "    'email-ctg-all': {'DataCol': 'email_ctg_all','Catenate': False,'RegExp': '[^0-9a-zA-Z\\.\\-\\_\\@\\|]+','Controlled': False},\n",
    "    'name-pi': {'DataCol': 'name_pi','Catenate': False,'RegExp': '','Controlled':False},\n",
    "    'email-customer': {'DataCol': 'email_customer','Catenate': False,'RegExp': '[^0-9a-zA-Z\\.\\-\\_\\@\\|]+','Controlled': False},\n",
    "    'Assay': {'DataCol': 'Assay','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'IndexAdapters': {'DataCol': 'IndexAdapters','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'Strandness': {'DataCol': 'Sample_Strandness','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'FragmentationTime': {'DataCol': 'fragmentation_time','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'PCR-cycles': {'DataCol': 'pcr_cycles','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'PairedEnd': {'DataCol': 'Sample_PairedEnd','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'PoolConcNovaSeq': {'DataCol': 'Pool_Conc_NovaSeq','Catenate': False,'RegExp': '','Controlled': True},\n",
    "    'PoolMolarityNovaSeq': {'DataCol': 'Pool_Molarity_NovaSeq','Catenate': False,'RegExp': '','Controlled': True}}\n",
    "\n",
    "# params_datacols - lookup dictionary for [Data] column -> [Header] param\n",
    "params_datacols=[params_dict[c]['DataCol'] for c in params_dict.keys()]\n",
    "params_datacols=dict.fromkeys(params_datacols)\n",
    "for c in params_dict.keys():\n",
    "    params_datacols[params_dict[c]['DataCol']]=c\n",
    "\n",
    "print(params_datacols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------\n",
    "##     FUNCTIONS \n",
    "## -------------------------------------\n",
    "\n",
    "## get csv type (if semicolon or comma)\n",
    "def find_csv_delimiter(sheet_name=None):\n",
    "    ## function to determine if csv file uses comma or semicolon as separator\n",
    "    ## simply counts the number of ',' and ';'. Who wins this battle will be thew winner\n",
    "    ## Input: csv file path\n",
    "    ## Output: a character - separator (',' or ';')\n",
    "\n",
    "  #sheet_name='/Users/david/tmp/CTG_SampleSheet.labsheet.test.csv'\n",
    "  print(f' ... determining csv file separator')\n",
    "  print(f' ... ... Reading: {sheet_name} ')\n",
    "\n",
    "  count_comma = 0\n",
    "  count_semic = 0\n",
    "  csvfile = open(sheet_name, \"r\")\n",
    "  for i in csvfile:\n",
    "    for c in i:\n",
    "      if c == ',': count_comma += 1\n",
    "      elif c == ';': count_semic += 1\n",
    "  csvfile.close()\n",
    "  print(f' ... ... {count_comma} commas vs  {count_semic} semicolons')\n",
    "  if count_comma >= count_semic:\n",
    "    return_char=','\n",
    "  else:\n",
    "    return_char=','\n",
    "  print(f' ... ... returning \"{return_char}\" ' )\n",
    "  return(return_char)\n",
    "\n",
    "\n",
    "## extract param function. Return value from second instance if found. else return blank\n",
    "def get_param(param_name=None, myDict=None):\n",
    "    if param_name in myDict.keys(): return(myDict[param_name][1])\n",
    "    else: return('')\n",
    "## end function\n",
    "\n",
    "\n",
    "## harmonize params ... \n",
    "def harmonize_header_params(input_row=None, data_mat=None, data_col=None, allowMultiple=None, ingoreBlanks=None):\n",
    "    ## function for harmonizing parameters that are present in [Header] and [Data] (individual samples)\n",
    "    ## [Header] and [Data] param pairs often do not have identical names\n",
    "    ## Main principle is to look at values in [Data] column and replace the [Header] with that value(s)\n",
    "    ##  - if unique value in [Data] - Replace!\n",
    "    ##  - if >1 value collapse 'multiple' (default), or separate values by comma.\n",
    "    return_row = input_row\n",
    "    if data_col in data_mat.columns.tolist():\n",
    "        if len(data_mat[data_col].unique())== 1:\n",
    "            return_row[1] = data_mat[data_col].tolist()[0]\n",
    "        else:\n",
    "            return_row[1] = 'multiple'\n",
    "            if allowMultiple==False:\n",
    "                raise ValueError(f'Error: Multiple values found in [Data] column \"{data_col}\" when harmonizing [Header] and [Data] params. Multiple values are not allowed within one and the same project as defined by the \"params_dict\" object in this python script. Values found were:  {data_mat[data_col].unique()}' )\n",
    "        if not return_row[1]==input_row[1]:\n",
    "            print(f' ... ... Harmonizing values. [Header] param \"{input_row[0]}\" changed from \"{input_row[1]}\" to [Data] \"{data_col}\" columns value: {return_row[1]}')\n",
    "        # if return_row[1]==input_row[1]: ## no action\n",
    "\n",
    "    return(return_row)\n",
    "    ## end function\n",
    "\n",
    "def replace_characters_foo(list_in=None, RegExp='[^0-9a-zA-Z\\_\\.\\-\\+\\@\\(\\)\\;\\,\\'\\\"\\| ]+', my_sub=''):\n",
    "    ## function to replace non-allowed characters with a character. \n",
    "    ## input is a list. loops thorugh the entire list\n",
    "    p = re.compile(RegExp)\n",
    "    list_out = list_in\n",
    "    l_index = 0\n",
    "    for list_i in list_in:\n",
    "        substring=p.sub(my_sub, list_i)    \n",
    "        if not substring == list_i:\n",
    "            print(f' ... ... ... Illegal character in \"{list_i}\". replacing with \"{substring}\"')\n",
    "            list_out[l_index]=substring\n",
    "        l_index+=1\n",
    "    # print(f'{list_out}')   \n",
    "    return(list_out)\n",
    "\n",
    "def replace_booleans_foo(list_in):\n",
    "    ## replace booleans with lowercase (fit for bash/nextflow scripting)\n",
    "    list_out = list_in\n",
    "    l_index = 0\n",
    "    for list_i in list_in:\n",
    "        if list_i.lower() in ['true','false']:\n",
    "            list_out[l_index]=list_i.lower()\n",
    "        l_index+=1\n",
    "    return(list_out)\n",
    "\n",
    "\n",
    "def read_samplesheet_section(sheet_name=None, sheet_section=None, section_is_dataframe=False, allowMultiple=False, RegExp='[^0-9a-zA-Z\\_\\.\\-\\+\\@\\(\\)\\;\\,\\'\\\"\\| ]+'):\n",
    "    ## function for reading the different sections in a IEM style sample sheet.\n",
    "    ## Each section is defined with a header brackets, such as [Header], [Data] etc\n",
    "    ## Input: a CTG style samplesheet\n",
    "    ##       accepts both comma and semicolon separated (determined using find_csv_delimiter function)\n",
    "    ## Output: a samplesheet section that is parsed/curated, to use/print in a parsed sampleheet by the ctg-parse-samplesheeet script\n",
    "    ## Behaviour: \n",
    "    ##   duplicate params/columns within a section is not allowed.\n",
    "    ##   params with (all) blank values are removed\n",
    "    ##   blank rows will always mark the end of a section, i.e. a section starts from its [Data] and ends at 1st blank row\n",
    "\n",
    "    ## Arguments:\n",
    "    ##   sheet_name: name of csv sample sheet\n",
    "    ##   sheet_section: section to parse and extract. Use brackets!!  \n",
    "    ##   section_type: argument (rows or matrix) will define how the section is read and returned\n",
    "    ##   RegExp: Allowed characters. A default regular expression to control allowed characters within this section. Here, the regexp is pretty inclusive, listing characters allowed over all sectionss. For more stringent regexp filtering add these steps later \n",
    "    ## \n",
    "    import csv\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import sys\n",
    "    import argparse\n",
    "\n",
    "    ## debugging:\n",
    "    # sheet_name='/Users/david/tmp/CTG_SampleSheet.labsheet.test.csv'\n",
    "    # section_is_dataframe=True\n",
    "    # sheet_section='[Data]'\n",
    "    # RegExp='[^0-9a-zA-Z\\_\\.\\-\\+\\@\\(\\)\\;\\,\\'\\\"\\| ]+'\n",
    "\n",
    "    ## Start function\n",
    "    ## --------------\n",
    "    n_rows=len(open(sheet_name).readlines())\n",
    "    print(f' ... Fetching {sheet_section} section from \"{sheet_name}\"')\n",
    "    print(f' ... ... ')\n",
    "    sheet_delim = find_csv_delimiter(sheet_name=sheet_name) # determine delimiter\n",
    "    \n",
    "\n",
    "    with open(sheet_name, 'r', encoding='utf-8-sig') as csvfile:\n",
    "        allines = csv.reader(csvfile, delimiter=(sheet_delim), quotechar='\"', skipinitialspace=True)    \n",
    "        myLine = 0\n",
    "        s_index = 0\n",
    "        read_section = False\n",
    "        myDict={} ## dictionary in which to store section to be read\n",
    "\n",
    "        ## main approach is to read until between given section header and 1st blank line\n",
    "        ## -------------------------------\n",
    "        print(f' ... ... Reading lines in SampleSheet ...')\n",
    "        print(f' ... ... (File is {n_rows} rows )')\n",
    "        for row in allines:\n",
    "            myLine+=1\n",
    "            if len(row) < 2: # quickfix for if csv file has no proper commas. causes problems if only the param listed but not followed by comma (and a value)\n",
    "                row.append('') # Append a blank value to the 'row' object (minimum length is 2)\n",
    "            \n",
    "            ## Read rows that span between section of interrest and first blank row after\n",
    "            if row[0] == sheet_section:\n",
    "                read_section = True\n",
    "                found_section = True\n",
    "                print(f' .. ... found supplied sheet_section header: {sheet_section} at line {myLine}')\n",
    "                print(f' ... ... ... reading data')\n",
    "                continue ## section header identified, continue reading next line and store (until blank line)\n",
    "            elif read_section == True and all(elem == '' for elem in row):\n",
    "                read_section = False\n",
    "                print(f' ... ... stopped reding at blank line: {myLine}')\n",
    "                continue\n",
    "            \n",
    "            ## If inbetween [section] and blank row\n",
    "            if read_section == True: ## parse this line and store in output dict\n",
    "                \n",
    "                # replace very illegal characters using replace_characters_foo\n",
    "                row = replace_characters_foo(list_in=row, RegExp='[\\,]', my_sub=' ') ## replacing commas if present\n",
    "                row = replace_characters_foo(list_in=row, RegExp='[\\s]+', my_sub=' ') ## replace all (including illegal spaces) with regular space\n",
    "                row = replace_characters_foo(list_in=row, RegExp=RegExp, my_sub='') ## replace all (including illegal spaces) with regular space\n",
    "                \n",
    "                # set any booleans to lowercase (true/false)\n",
    "                row = replace_booleans_foo(row)\n",
    "\n",
    "                if not section_is_dataframe:\n",
    "                    ## If this section is not a matrix/data frame. Then expext one value per parameter (row)\n",
    "                    ## <parameter>,<value>, ... i.e. row[0] is the parameter and row[1] is the value\n",
    "                    ## store the row[1] in the output dict key row[0]. Raise error & exit if param already has been read\n",
    "                    if row[0] in myDict.keys():\n",
    "                        raise ValueError(f' ... ... ... Error: Duplicate {sheet_section} parameter found: \"{row[0]}\"')                \n",
    "                    ## Store parameter value in myDict dictionary (dict key is the paramter) \n",
    "                    myDict[row[0]] = row[1]\n",
    "                    print(f' ... ... ... read param:  {row[0]}')\n",
    "\n",
    "                elif section_is_dataframe:\n",
    "                    ## If data frame type of section. first import into dictionary (use s_index as row index)                \n",
    "                    ## First row will become header - do not allow any special characters other than underscore here\n",
    "                    if s_index == 0:\n",
    "                        print(f' ... ... ... reading header row for data frame. ')\n",
    "                        print(f' ... ... ... ... allow ony underscore as special character')\n",
    "                        row = replace_characters_foo(list_in=row, RegExp='[^0-9a-zA-Z\\_+]', my_sub='') ## replace all (including illegal spaces) with regular space\n",
    "                        print(row)\n",
    "                    myDict[s_index] = row\n",
    "                    # print(f' ... ... ... read data frame row:  {s_index}')\n",
    "            s_index += 1\n",
    "        print(f' ... ... ok ')\n",
    "        \n",
    "        ## All data is read. Now crunch dictionary into panda data frame if section is df\n",
    "        if section_is_dataframe and found_section:\n",
    "            # generate Pandas Data Frame \n",
    "            print(f' ... ... section_is_dataframe set to true:')\n",
    "            print(f' ... ... ... generating pandas dataframe')\n",
    "            df = pd.DataFrame(myDict)\n",
    "            df = df.transpose() # transpose from dict\n",
    "            df.rename(columns=df.iloc[0], inplace=True) # first [Data] row is headers\n",
    "            df = df.iloc[1: , :]\n",
    "            print(f' ... returning data frame with dimensions: {df.shape}')\n",
    "            return(df)\n",
    "        elif section_is_dataframe and found_section:\n",
    "            print(f' ... returning dictionary')\n",
    "            return(myDict)\n",
    "        else:\n",
    "            print(f' ... section header {sheet_section} not found. returning \"\"')\n",
    "            return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86ae8d00f1e1fb3c14c29e89974f090ac94d8c530ff6d21617d384d057ded9db"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('ctg-parse-samplesheet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
